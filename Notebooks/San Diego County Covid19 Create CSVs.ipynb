{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COVID_19_Race_and_Ethnicity_Statistics_San_Diego_County.csv\n",
      "COVID_19_Hospitalization_Statistics_San_Diego_County.csv\n",
      "COVID_19_Death_Statistics_San_Diego_County.csv\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from urllib.parse import urljoin\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "#Where to save compiled csv file\n",
    "local_folder = \"C:/Data/SDCovid/Dailies/\"\n",
    "#location of our data\n",
    "folder_url = 'http://shulok.com/SD_Covid_data/'\n",
    "\n",
    "#get the contents of the folder\n",
    "url = requests.get(folder_url).text\n",
    "soup = BeautifulSoup(url)\n",
    "\n",
    "dateformat = \"%m-%d-%Y\"\n",
    "\n",
    "#Date to switch to skipping 2 rows in the race csv file due to data changes\n",
    "switch_date = dt.datetime(2020,6,25)\n",
    "\n",
    "raceframes = []\n",
    "hospframes = []\n",
    "deathframes = []\n",
    "\n",
    "def DateFromFileName(link, pos):\n",
    "    #Break up the file name by space\n",
    "    mylist = link.split(\"%20\")\n",
    "    \n",
    "    #get file date which is right before the file extension\n",
    "    datestr = mylist[pos].split('.')[0]\n",
    "    \n",
    "    #It includes data up to the day before the file date, so subtract a day\n",
    "    date = dt.datetime.strptime(datestr, dateformat) - dt.timedelta(days=1)\n",
    "    return date\n",
    "        \n",
    "def ProcessRaceFile(link):\n",
    "    skip_nrows = 1\n",
    "    date = DateFromFileName(link, 5)\n",
    "    \n",
    "    if date > switch_date:\n",
    "        skip_nrows = 2\n",
    "\n",
    "    # Read the source file, but use the first column as an index\n",
    "    df = pd.read_csv(folder_url + link, skiprows=skip_nrows)\n",
    "\n",
    "    #The file date is the date when the data was updated\n",
    "    df['Date'] = date\n",
    "    df.columns = ['Race and Ethnicity', 'Count', '% with known Race/Ethnicity', 'per 100k', 'Date']\n",
    "\n",
    "    return df\n",
    "    \n",
    "def ProcessFile(link, pos):\n",
    "    date = DateFromFileName(link, pos)\n",
    "    \n",
    "    # Read the source file, but use the first column as an index\n",
    "    df = pd.read_csv(folder_url + link, index_col=0)\n",
    "\n",
    "    # Transpose the frame, which puts the row lables as column labels. \n",
    "    df = df.T\n",
    "\n",
    "    #The file date is the date when the data was updated\n",
    "    df['date'] = date\n",
    "\n",
    "    return df\n",
    "        \n",
    "def CombineRaceFiles():\n",
    "    df = pd.concat(raceframes, sort=True) # Concatenate all of the transposed frames\n",
    "\n",
    "    #reorder the columns\n",
    "    df=df.reindex(columns= ['Date', 'Race and Ethnicity', 'Count', '% with known Race/Ethnicity', 'per 100k'])\n",
    "\n",
    "    df.sort_values(by=['Date'], inplace=True, ascending=True)\n",
    "\n",
    "    filename = 'COVID_19_Race_and_Ethnicity_Statistics_San_Diego_County.csv'\n",
    "    print(filename)\n",
    "\n",
    "    df.to_csv(local_folder + filename, index=False)\n",
    "    \n",
    "def CombineFiles(frames, filename):\n",
    "    df = pd.concat(frames, sort=True) # Concatenate all of the transposed frames\n",
    "\n",
    "    # Move the date column to the front. \n",
    "    date_col = df.pop('date')\n",
    "    df.insert(0,'date',date_col)\n",
    "\n",
    "    df.sort_values(by=['date'], inplace=True, ascending=True)\n",
    "\n",
    "    print(filename)\n",
    "\n",
    "    df.to_csv(local_folder + filename, index=False)# The index column is useless, so drop it. \n",
    "    df.head()\n",
    "    \n",
    "for link in soup.findAll(\"a\"):\n",
    "    current_link = link.get(\"href\")\n",
    "    if current_link.endswith('csv'):\n",
    "        if current_link.count('Ethnicity') == 1:\n",
    "            raceframes.append(ProcessRaceFile(current_link))\n",
    "        elif current_link.count('Hospitalizations') == 1:\n",
    "            hospframes.append(ProcessFile(current_link, 3))\n",
    "        elif current_link.count('Deaths') == 1:\n",
    "            deathframes.append(ProcessFile(current_link, 4))\n",
    "            \n",
    "CombineRaceFiles()\n",
    "CombineFiles(hospframes, 'COVID_19_Hospitalization_Statistics_San_Diego_County.csv')\n",
    "CombineFiles(deathframes, 'COVID_19_Death_Statistics_San_Diego_County.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
